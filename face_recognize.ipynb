{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arjun', 'dadi', 'karan', 'mummy']\n"
     ]
    }
   ],
   "source": [
    "base_dir = r\"C:\\Users\\user\\Documents\\anaconda scripts\\project 2.0\\Face_Database\"\n",
    "train_dir=os.path.join(base_dir,\"training_set\")\n",
    "validation_dir=os.path.join(base_dir,\"cross_val_set\")\n",
    "names = os.listdir(train_dir)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 4 classes.\n",
      "Found 96 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                  train_dir,\n",
    "                  target_size=(150,120),\n",
    "                  batch_size=20,\n",
    "                  color_mode=\"rgb\",\n",
    "                  class_mode='categorical')\n",
    "validation_generator=validation_datagen.flow_from_directory(\n",
    "                  validation_dir,\n",
    "                  target_size=(150,120),\n",
    "                  batch_size=16,\n",
    "                  color_mode=\"rgb\",\n",
    "                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(150,120,3)),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dense(units=4, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 - 16s - loss: 1.3222 - accuracy: 0.3810 - val_loss: 0.8952 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "50/50 - 15s - loss: 0.8991 - accuracy: 0.6150 - val_loss: 0.4191 - val_accuracy: 0.8646\n",
      "Epoch 3/10\n",
      "50/50 - 15s - loss: 0.7373 - accuracy: 0.6990 - val_loss: 0.1619 - val_accuracy: 0.9583\n",
      "Epoch 4/10\n",
      "50/50 - 15s - loss: 0.4120 - accuracy: 0.8270 - val_loss: 0.3442 - val_accuracy: 0.8229\n",
      "Epoch 5/10\n",
      "50/50 - 15s - loss: 0.3028 - accuracy: 0.8790 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "50/50 - 15s - loss: 0.2382 - accuracy: 0.9120 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "50/50 - 15s - loss: 0.1335 - accuracy: 0.9500 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "50/50 - 16s - loss: 0.0763 - accuracy: 0.9700 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "50/50 - 15s - loss: 0.2092 - accuracy: 0.9220 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "50/50 - 16s - loss: 0.0535 - accuracy: 0.9850 - val_loss: 9.3041e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=50,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=6,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facedetect=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#img=cv2.imread(r\"C:\\Users\\user\\Pictures\\Camera Roll\\WIN_20200712_23_14_02_Pro.jpg\")\n",
    "img=cv2.imread(r\"C:\\Users\\user\\Documents\\anaconda scripts\\project 2.0\\Face_Database\\training_set\\karan\\karan.0.jpg\")\n",
    "cv2.imshow(\"face\",img)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "faces=facedetect.detectMultiScale(gray,1.1,5)\n",
    "for(x,y,w,h)in faces:\n",
    "    IMG = img[y-50:y+h+35,x-10:x+w+10]\n",
    "    cv2.imshow(\"face\",IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facedetect=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while(True):\n",
    "    ret,img=cap.read()\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=facedetect.detectMultiScale(gray,1.1,5)\n",
    "    for(x,y,w,h)in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        IMG = img[y-50:y+h+35,x-10:x+w+10]\n",
    "        IMG = cv2.resize(img,(120,150))\n",
    "        IMG = np.array(IMG)\n",
    "        IMG=IMG/255\n",
    "        IMG.resize((1,150,120,3))\n",
    "        #pil_IMG = Image.fromarray(IMG)\n",
    "        #pil_IMG.show()\n",
    "        #pil_IMG=Image.fromarray(img[y-50:y+h+35,x-10:x+w+10])\n",
    "        #pil_IMG.show()\n",
    "        #IMG = pil_IMG.resize((150,120))\n",
    "        #IMG = np.array(IMG)\n",
    "        #IMG=IMG/255\n",
    "        #IMG.resize((1,150,120,3))\n",
    "        classes=model.predict(IMG)\n",
    "        labels = list(classes[0])\n",
    "        maxpos = labels.index(max(labels))\n",
    "        name = names[maxpos]\n",
    "        #print(maxpos)\n",
    "        #print(labels[maxpos])\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "        cv2.putText(img,name,(x,y+h),font,1,(0,255,0),2)\n",
    "    cv2.imshow(\"Face\",img)\n",
    "    if(cv2.waitKey(1)==ord('q')):\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
